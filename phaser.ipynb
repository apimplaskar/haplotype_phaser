{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CS 124: Machine Learning in Genetics\n",
    "# Project: Haplotype Phaser\n",
    "# Contributors: Aditya Pimplaskar, Aditya Joglekar\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation functions\n",
    "def fillna(col):\n",
    "    if col.value_counts().index[0] == '1':\n",
    "        col.fillna(col.value_counts().index[1], inplace=True) # ensure we don't fill heterozygous\n",
    "    else:\n",
    "        col.fillna(col.value_counts().index[0], inplace=True)\n",
    "    return col\n",
    "\n",
    "def imputeData(df):\n",
    "    df = df.replace('*', np.NaN)\n",
    "    #df = df.astype('int64')\n",
    "    #imputer = SimpleImputer(missing_values=np.nan, strategy= 'most_frequent')\n",
    "    #return pd.DataFrame(imputer.fit_transform(df))\n",
    "    return df.apply(lambda col:fillna(col))\n",
    "\n",
    "def splitDF(df, numPieces): \n",
    "    return np.array_split(df, numPieces)\n",
    "    \n",
    "def imputeData2(df, chunkSize):\n",
    "    df = df.replace('*', np.NaN)\n",
    "    splits = splitDF(df, len(df) // chunkSize + 1) # splits data frame into pieces of length 100\n",
    "    for dfi in splits:\n",
    "        dfi = dfi.T\n",
    "        dfi.apply(lambda col:fillna(col)) # fill with most common SNP value for that chunk\n",
    "    return splits #returns list of split up data frames\n",
    "\n",
    "def deleteDups(g):\n",
    "    # goal is to eliminate duplicate genotypes/duplicate haplotypes\n",
    "    g.drop_duplicates(inplace=True)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compatibility checker function\n",
    "def checkPhase(g, h1, h2):\n",
    "    # want to see if element wise sum of h1 and h2 is g\n",
    "    # takes list g of SNPs\n",
    "    # takes lists h1, h2 of SNPs\n",
    "    import numpy as np\n",
    "    g = np.array(g)\n",
    "    h1 = np.array(h1)\n",
    "    h2 = np.array(h2)\n",
    "    comparison =  (h1 + h2 == g)\n",
    "    return comparison.all()\n",
    "\n",
    "def findDifference(g, h1): \n",
    "    # so that we can fill in a new haplo if we don't find a compatibile pair in Clark's\n",
    "    g = np.array(g)\n",
    "    h1 = np.array(h1)\n",
    "    return (g - h1).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clarks(genotypes):\n",
    "    #input: genotype dataframe\n",
    "    \n",
    "    # need to give a starting pool\n",
    "    # we can do this by phasing all of the deterministic genotypes\n",
    "    genotypes = genotypes.astype('int64')\n",
    "    haplotypes = []\n",
    "\n",
    "    toDrop = [] # deterministic\n",
    "    for ind in range(len(genotypes)):\n",
    "        h = []\n",
    "        g = genotypes.iloc[ind]\n",
    "        for i in range(len(g)):\n",
    "            if g[i] == 1: #non deterministic\n",
    "                break\n",
    "            if g[i] == 0:\n",
    "                h.append(0)\n",
    "            if g[i] == 2:\n",
    "                h.append(1)\n",
    "        if len(h) == len(g): # did you make it to the end of the string\n",
    "            haplotypes.append(h)\n",
    "            toDrop.append(ind) #thins out our new genotype list\n",
    "    genotypes = genotypes.drop(genotypes.index[toDrop])\n",
    "\n",
    "    for i,g in genotypes.iterrows():\n",
    "        phased = False #flag variable\n",
    "        for h1 in range(len(haplotypes)):\n",
    "            for h2 in range(h1, len(haplotypes)):\n",
    "                if checkPhase(g,haplotypes[h1],haplotypes[h2]): # we already have the phase accounted for\n",
    "                    # somewhere here, need to output that these two h1, h2 make that genotype!\n",
    "                    \n",
    "                    phased = True\n",
    "        if phased == False: # now we need to add a haplo that works\n",
    "            for h in haplotypes:\n",
    "                diff = findDifference(g, h)\n",
    "                # now just need to make sure this difference has no weird values -- i.e. is a valid addition\n",
    "                if sum(0 <= x <= 1 for x in diff) == len(g):\n",
    "                    haplotypes.append(h)\n",
    "                 # somewhere here, need to output that these two h and diff make that genotype!\n",
    "                    break\n",
    "    return haplotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clarksSplit(genotypes):\n",
    "    #input: list of split up dataframes\n",
    "    all_haps = []\n",
    "    phases = [[] for i in range(len(genotypes[0].columns))]\n",
    "    # need to give a starting pool\n",
    "    # we can do this by phasing all of the deterministic genotypes\n",
    "    last_ind = 0\n",
    "    \n",
    "    for dfindex in range(len(genotypes)):\n",
    "        \n",
    "        #print(\"index of subdataframe: \", dfindex)\n",
    "        dfi = genotypes[dfindex]\n",
    "        dfi = dfi.T\n",
    "        dfi = dfi.astype('int64')\n",
    "        index_update = 0\n",
    "        #print(\"shape of subdata frame: \", dfi.shape)\n",
    "        \n",
    "        haplotypes = []\n",
    "        subphases = []\n",
    "        \n",
    "        toDrop = [] # deterministic\n",
    "        for ind in range(len(dfi)):\n",
    "            #print(\"current individual: \", ind)\n",
    "            h = []\n",
    "            g = dfi.iloc[ind]\n",
    "            index_update = len(g)\n",
    "            for i in range(len(g)):\n",
    "                print(\"length of partial genotype \", len(g))\n",
    "                #adj_i = (chunkSize*dfindex + i)# need to adjust indexing\n",
    "                adj_i = last_ind + i \n",
    "                print(\"adjusted index\", adj_i)\n",
    "                if g[adj_i] == 1: #non deterministic\n",
    "                    break\n",
    "                if g[adj_i] == 0:\n",
    "                    h.append(0)\n",
    "                if g[adj_i] == 2:\n",
    "                    h.append(1)\n",
    "            if len(h) == len(g): # did you make it to the end of the string\n",
    "                haplotypes.append(h)\n",
    "                phases[ind].append((h,h))\n",
    "                # to subphases\n",
    "                #subphases.append((h,h))\n",
    "                \n",
    "                \n",
    "                \n",
    "                toDrop.append(ind) #thins out our new genotype list\n",
    "        last_ind += index_update\n",
    "        #print(\"last index\", last_ind)\n",
    "        dfi = dfi.drop(dfi.index[toDrop])\n",
    "\n",
    "        for i,g in dfi.iterrows():\n",
    "            phased = False #flag variable\n",
    "            for h1 in range(len(haplotypes)):\n",
    "                for h2 in range(h1, len(haplotypes)):\n",
    "                    if checkPhase(g,haplotypes[h1],haplotypes[h2]): # we already have the phase accounted for\n",
    "                        # need to store that h1 and h2 phase that genotype \n",
    "                        phases[i].append((haplotypes[h1], haplotypes[h2]))\n",
    "                        # to subphases\n",
    "                        #subphases.append((haplotypes[h1],haplotypes[h2]))\n",
    "                        \n",
    "                        \n",
    "                        phased = True\n",
    "            if phased == False: # now we need to add a haplo that works\n",
    "                for h in haplotypes:\n",
    "                    diff = findDifference(g, h)\n",
    "                    # now just need to make sure this difference has no weird values -- i.e. is a valid addition\n",
    "                    if sum(0 <= x <= 1 for x in diff) == len(g):\n",
    "                        haplotypes.append(h)\n",
    "                        # need to store that h and diff phase genotype\n",
    "                        # to subphases\n",
    "                        #subphases.append((h,diff))\n",
    "                        \n",
    "                        \n",
    "                        phases[i].append((h, diff))\n",
    "                        break\n",
    "        all_haps.append(haplotypes)\n",
    "        #phases[ind].append(subphases)\n",
    "    #return all_haps\n",
    "    return phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(phases):\n",
    "    # this function takes in the output of our splitClarks method\n",
    "    # input: phases -- a list of a list of  of tuples \n",
    "        # outer list accounts for all 50 individuals\n",
    "        # inner list 1 accounts for all sub-phasings of that individual\n",
    "        # each tuple is the phase for that sub-array\n",
    "    # output: the output desired for the project\n",
    "        # one table with every two columns representing the phase of one individual\n",
    "        # 1st and 2nd column of output = phase of 1st individual\n",
    "        # etc.\n",
    "    to_cast = [[] for i in range(len(phases) * 2)] # will be cast to pandas data frame --> transposed --> printed to file as a table    \n",
    "    for i in range(len(phases)): # for one particular individual\n",
    "        current = phases[i] #\n",
    "        for j in range(0, len(current),2): # for one particular list of tuples\n",
    "            to_cast[i].extend(current[j][0])\n",
    "            to_cast[i+1].extend(current[j][1])\n",
    "    \n",
    "    to_cast = pd.DataFrame(to_cast)\n",
    "    to_cast = to_cast.T\n",
    "    #to_cast.to_csv('phased.txt', sep = \" \", header = False)\n",
    "    return to_cast\n",
    "    #  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper(genotypes):\n",
    "    # do it all\n",
    "    #genotypes = genotypes.T\n",
    "    #genotypes = imputeData(genotypes) 3# impute\n",
    "    genotypes = imputeData2(genotypes, 5)\n",
    "    genotypes = genotypes.astype('int64')\n",
    "    deleteDups(genotypes) # get rid of duplicates\n",
    "    return clarks(genotypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39496, 50)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex1 = pd.read_csv(\"assignment/example_data_1_masked.txt\", sep = \" \", header=None)\n",
    "ex1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed = imputeData2(ex1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99407535, 0.98817602, 0.98987239, 0.99326514, 0.99415131,\n",
       "       0.99415131, 0.99450577, 0.99399939, 0.99475896, 0.99468301,\n",
       "       0.99432854, 0.9948096 , 0.99450577, 0.99402471, 0.9944045 ,\n",
       "       0.99382216, 0.99508811, 0.99377152, 0.99478428, 0.99412599,\n",
       "       0.99448045, 0.99501215, 0.99486024, 0.99417663, 0.99405003,\n",
       "       0.99432854, 0.99448045, 0.99415131, 0.99501215, 0.99437918,\n",
       "       0.9953413 , 0.99405003, 0.99445513, 0.99410067, 0.99554385,\n",
       "       0.99415131, 0.99326514, 0.99402471, 0.99377152, 0.9937462 ,\n",
       "       0.99356897, 0.99311323, 0.99455641, 0.99473364, 0.99463237,\n",
       "       0.99470832, 0.99455641, 0.99402471, 0.99554385, 0.99465769])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check accuracy\n",
    "ex1.un = pd.read_csv(\"assignment/example_data_1.txt\", sep = \" \", header = None)\n",
    "imputedFull = pd.concat(imputed)\n",
    "imputedFull = imputedFull.astype('int64')\n",
    "booleanMaskDisc = pd.DataFrame(imputedFull == ex1.un)\n",
    "maskedCorrectlyCounts = booleanMaskDisc.apply(pd.Series.value_counts, axis = 0)\n",
    "np.array(maskedCorrectlyCounts.iloc[0])/(np.array(maskedCorrectlyCounts.iloc[1]) + np.array(maskedCorrectlyCounts.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39496, 50)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputedFull.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 39496)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputedFull = imputedFull.T\n",
    "imputedFull.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 39496)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deleteDups(imputedFull)\n",
    "imputedFull.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70     0\n",
       "71     0\n",
       "72     0\n",
       "73     2\n",
       "74     0\n",
       "75     0\n",
       "76     2\n",
       "77     0\n",
       "78     2\n",
       "79     2\n",
       "80     2\n",
       "81     0\n",
       "82     0\n",
       "83     2\n",
       "84     2\n",
       "85     1\n",
       "86     0\n",
       "87     2\n",
       "88     0\n",
       "89     1\n",
       "90     1\n",
       "91     2\n",
       "92     1\n",
       "93     2\n",
       "94     1\n",
       "95     0\n",
       "96     1\n",
       "97     1\n",
       "98     1\n",
       "99     1\n",
       "      ..\n",
       "110    2\n",
       "111    1\n",
       "112    2\n",
       "113    1\n",
       "114    0\n",
       "115    1\n",
       "116    0\n",
       "117    1\n",
       "118    2\n",
       "119    2\n",
       "120    2\n",
       "121    1\n",
       "122    2\n",
       "123    2\n",
       "124    0\n",
       "125    0\n",
       "126    0\n",
       "127    2\n",
       "128    0\n",
       "129    2\n",
       "130    0\n",
       "131    1\n",
       "132    2\n",
       "133    0\n",
       "134    0\n",
       "135    0\n",
       "136    2\n",
       "137    0\n",
       "138    1\n",
       "139    1\n",
       "Name: 1, Length: 70, dtype: int64"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#these stats only for 70\n",
    "len(imputed) # 565 sub data frames for 70\n",
    "d = imputed[1]\n",
    "d = d.T\n",
    "d.shape #50 individuals on the rows, 70 SNPs on the columms\n",
    "g = d.iloc[1]\n",
    "g = g.astype('int64')\n",
    "len(g) #70 SNPs per person, switches to 69 at some point\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clarksSplit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fe35e3decc39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrialrun_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclarksSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimputed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'clarksSplit' is not defined"
     ]
    }
   ],
   "source": [
    "trialrun_1 = clarksSplit(imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trialrun_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7dcce7051fd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrialrun_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trialrun_1' is not defined"
     ]
    }
   ],
   "source": [
    "trialrun_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 0\n",
    "for i in trialrun_1:\n",
    "    if not len(i)  == 0:\n",
    "        n+=1\n",
    "        \n",
    "n\n",
    "    # chunk size 100 g_ives 200 subarrays' phases \n",
    "    # chunk size 70 gives 366 subarrays' phases\n",
    "    # chunk size 40 gives 820/988 subarrays' phases\n",
    "    # chunk size 15 gives 2593/2634 subarrays' phases\n",
    "    # chunk size 10 gives 3935/3950 subarrays' phases\n",
    "    # chunk size 7 gives 5642/5643 phasings!\n",
    "    # chunk size 5 gives 7900/7900 phasings!\n",
    "    \n",
    "    \n",
    "### KEEP TESTING!\n",
    "## Smaller chunk sizes\n",
    "    ## we do this simply by passing the right chunk size into the imputer\n",
    "    ## after that its just a matter of running clarksSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find a way to combine these phasingsn\n",
    "# psuedocode:\n",
    "# for i from 0 to number of rows in largest subarray\n",
    "    # tack on each subarray's [i%subarray length] row\n",
    "\n",
    "# number of phasings we should get in total  == the number of rows in the largest subarray\n",
    "\n",
    "maxlen = 0\n",
    "minlen = 0\n",
    "for i in trialrun_1:\n",
    "    if i == 0: \n",
    "        minlen = len(i)\n",
    "    length = len(i)\n",
    "    if length > maxlen:\n",
    "        maxlen = length\n",
    "minlen #50\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [0], []]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [[] for i in range(3)]\n",
    "x[1].append(0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "haplotypes = [[] for i in range(maxlen)]\n",
    "\n",
    "for i in range(maxlen):\n",
    "    for j in trialrun_1:\n",
    "        haplotypes[i].extend(j[i%len(j)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imputed[7899].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 2), (2, 3), (3, 3)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [(2,2)]\n",
    "a.append((2,3))\n",
    "a\n",
    "h = 3\n",
    "a.append((h,h))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "extest = ex1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, -1, 0]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findDifference([1,2,3], [1,3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1\n",
       "0  2  3\n",
       "1  3  4"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([[2,3],[3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "14\n",
      "16\n",
      "18\n",
      "20\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "30\n",
      "32\n",
      "34\n",
      "36\n",
      "38\n",
      "40\n",
      "42\n",
      "44\n",
      "46\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,50,2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_cast = [[],[]]\n",
    "current = trialrun_1[0]\n",
    "for j in range(0, len(current),2): # for one particular list of tuples\n",
    "    to_cast[0].extend(current[j][0])\n",
    "    to_cast[1].extend(current[j][1])\n",
    "len(to_cast[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imputed[0].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
